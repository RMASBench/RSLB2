#########################################
# PLATFORM SETTINGS
#########################################

kernel.host: localhost
kernel.port: 7000


#########################################
# AGENT BEHAVIOR
#########################################

# When this is true, agents will only approach 
# targets selected by the station (which simulates the decentralize assignment)
# Otherwise they search for targets on their own.
agent.only_assigned: true

# Define here the planner to use
# agents.search.class: RSLBench.Search.AStar
agent.search.class: RSLBench.Search.BreadthFirstSearch

# Whether to perform interteam coordination or not
agent.interteam: true


#########################################
# UTILITY SETTINGS
#########################################

# Utility function to use
util.class: RSLBench.Helpers.Utility.ThirdUtilityFunction

# Trade-off between building utility and distance utility
# The bigger the value the bigger the influence of distance.
util.trade_off: 10

# Area covered by a single fire brigade.
# This is the major parameter when deciding the maximum number of agents
# to assign to a single fire.
util.fire_brigade_area: 200

# Penalty applied to blocked target fires (M in the paper)
util.blockade.fire_penalty: 100

# Penalty applied to blocked target blockades (Q in the paper)
util.blockade.police_penalty: 50

# Hysteresis factor to prevent target switching due to pathing issues
# The higher the factor, the higher the stickiness.
util.hysteresis: 1.1

# Parameters for the workload model.
# Whenever a fire with a required number of agents M gets
# N assigned agents and N>M, then there is a utility penalty
# of k*(N-M)^alpha
util.k: 2
util.alpha: 1.4

#########################################
# EXPERIMENT SETTINGS
#########################################

# Path to the results folder
results.path: results/

# Path to the cache folder
cache.path: cache/

# When should agents start acting
experiment.start_time: 23

# When should the experiment finish.
experiment.end_time: 300

# Whether to export each step's problem (in terms of utilities) or not
export: no
export.path: export/

# Whether to prune the fire brigades to fires graph, and to which per-node degree
problem.prune: no
problem.max_neighbors: 4

# Number of iterations to run the DCOP algorithm at each step of the roborescue simulation
# For instance, DSA agents will run for 100 iterations before making a final decision
dcop.iterations: 100

# If enabled, the DCOP solvers will employ an "anytime" check, so that their reported assignment
# will be the best of all assignments they have gone through during the solving process.
dcop.anytime: yes

# If enabled, DCOP solvers will make a final sequential pass through all agents, using a greedy
# procedure where each agent can change its choice depending on what others have chosen. This
# procedure is guaranteed to never decrease the solution quality, but has the noticeable cost
# of requiring n_agents extra iterations (because of the sequential nature of this correction)
dcop.greedy_correction: yes

# Fully qualified class of the solver
solver.class: RSLBench.Algorithms.BMS.BinaryMaxSum
solver.time: 1000

# Additional solvers to test
# Warning: the numbers must be in sequence!
solver.1.class: RSLBench.Algorithms.NewMS.MaxSum
solver.1.time: 3000
solver.2.class: RSLBench.Algorithms.DSA.DSA
solver.2.time: 500
solver.3.class: RSLBench.Algorithms.Random.Random
solver.3.time: 100
solver.4.class: RSLBench.Algorithms.Greedy.Greedy
solver.4.time: 100
solver.5.class: RSLBench.Algorithms.Closest.Closest
solver.5.time: 100


#########################################
# ALGORITHM-SPECIFIC SETTINGS
#########################################

# DSA probability of change
dsa.probability: 0.6

# Max-Sum damping factor, from 0 (no damping) to 1 (completely ignore messages)
maxsum.damping: 0.1
